I"÷]<p><code class="highlighter-rouge">kubeadm</code>æ˜¯ä¸€ä¸ªkuberneteså®˜æ–¹æä¾›çš„å¿«é€Ÿå®‰è£…å’Œåˆå§‹åŒ–æ‹¥æœ‰æœ€ä½³å®è·µ.ç›®å‰å·²ç»GAã€‚HAæ–¹æ¡ˆè¿˜æ²¡GAã€‚</p>

<h2 id="centos73åŸºäºkubeadmå®‰è£…kubernetes1134">Centos7.3åŸºäºkubeadmå®‰è£…kubernetes1.13.4</h2>

<h3 id="ç³»ç»Ÿç¯å¢ƒ">ç³»ç»Ÿç¯å¢ƒ</h3>
<ul>
  <li>Centos7 å†…æ ¸ç‰ˆæœ¬3.10.0-514</li>
  <li>2GBæˆ–è€…ä»¥ä¸Šçš„RAM(å¦åˆ™å°†æ²¡æœ‰è¶³å¤Ÿç©ºé—´ç•™ç»™app).</li>
  <li>2æ ¸ä»¥ä¸ŠCPU.</li>
  <li>é›†ç¾¤çš„æœºå™¨ä¹‹é—´å¿…é¡»èƒ½é€šè¿‡ç½‘ç»œäº’ç›¸é€šä¿¡.</li>
  <li>SWAPå¿…é¡»è¢«å…³é—­ï¼Œå¦åˆ™kubeletä¼šå‡ºé”™ï¼</li>
</ul>

<h3 id="å®‰è£…å‰å‡†å¤‡">å®‰è£…å‰å‡†å¤‡</h3>
<p><strong>1.å…³é—­selinux</strong></p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>setenforce 0
<span class="nv">$ </span><span class="nb">sed</span> <span class="nt">-i</span> <span class="s1">'s/^SELINUX=enforcing$/SELINUX=disabled/'</span> /etc/selinux/config
</code></pre></div></div>

<p><strong>2.æ·»åŠ netfilteræ¨¡å—</strong></p>

<blockquote>
  <p>CentOS 7ä¸Šçš„iptablesè¢«ç»•è¿‡è€Œå¯¼è‡´æµé‡è·¯ç”±ä¸æ­£ç¡®çš„é—®é¢˜ï¼Œéœ€è¦æŠŠnet.bridge.bridge-nf-call-iptablesåœ¨sysctlé…ç½®ä¸­è®¾ç½®ä¸º1</p>
</blockquote>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>$ cat &lt;&lt;EOF &gt;  /etc/sysctl.d/k8s.conf
net.bridge.bridge-nf-call-ip6tables = 1
net.bridge.bridge-nf-call-iptables = 1
EOF

$ sysctl -p /etc/sysctl.d/k8s.conf
</code></pre></div></div>
<p>ç¡®ä¿br_netfilteråœ¨æ­¤æ­¥éª¤ä¹‹å‰åŠ è½½äº†æ¨¡å—ã€‚è¿™å¯ä»¥é€šè¿‡è¿è¡Œæ¥å®Œæˆ<code class="highlighter-rouge">lsmod | grep br_netfilter</code>ã€‚è¦åŠ è½½å®ƒæ˜¾å¼è°ƒç”¨<code class="highlighter-rouge">modprobe br_netfilter</code>ã€‚</p>

<p><strong>3.å®‰è£…docker</strong></p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>$ sudo yum install docker-ce docker-ce-cli containerd.io
</code></pre></div></div>

<p><strong>4.é…ç½®docker cgroupdriver</strong></p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>systemctl <span class="nb">cat </span>docker
<span class="c"># /usr/lib/systemd/system/docker.service</span>
<span class="o">[</span>Unit]
<span class="nv">Description</span><span class="o">=</span>Docker Application Container Engine
<span class="nv">Documentation</span><span class="o">=</span>https://docs.docker.com
<span class="nv">After</span><span class="o">=</span>network-online.target firewalld.service
<span class="nv">Wants</span><span class="o">=</span>network-online.target
<span class="o">[</span>Service]
<span class="nv">Type</span><span class="o">=</span>notify
<span class="nv">EnvironmentFile</span><span class="o">=</span>-/run/flannel/docker
<span class="nv">ExecStart</span><span class="o">=</span>/usr/bin/dockerd <span class="nt">--exec-opt</span> native.cgroupdriver<span class="o">=</span>systemd <span class="se">\</span>
<span class="nv">ExecReload</span><span class="o">=</span>/bin/kill <span class="nt">-s</span> HUP <span class="nv">$MAINPID</span>
<span class="nv">LimitNOFILE</span><span class="o">=</span>infinity
<span class="nv">LimitNPROC</span><span class="o">=</span>infinity
<span class="nv">LimitCORE</span><span class="o">=</span>infinity
<span class="nv">TimeoutStartSec</span><span class="o">=</span>0
<span class="nv">Delegate</span><span class="o">=</span><span class="nb">yes
</span><span class="nv">KillMode</span><span class="o">=</span>process
<span class="nv">Restart</span><span class="o">=</span>on-failure
<span class="nv">StartLimitBurst</span><span class="o">=</span>3
<span class="nv">StartLimitInterval</span><span class="o">=</span>60s

<span class="o">[</span>Install]
<span class="nv">WantedBy</span><span class="o">=</span>multi-user.target
<span class="o">[</span>Service]
<span class="nv">EnvironmentFile</span><span class="o">=</span>-/run/flannel/docker
</code></pre></div></div>

<p><strong>5.å¯åŠ¨docker</strong></p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>$ systemctl enabel docker
$ systemctl start docker
</code></pre></div></div>

<p><strong>6.å®‰è£…kubeadmã€kubectlã€kubelet</strong></p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>$ cat &lt;&lt;EOF &gt; /etc/yum.repos.d/kubernetes.repo
[kubernetes]
name=Kubernetes
baseurl=https://packages.cloud.google.com/yum/repos/kubernetes-el7-x86_64
enabled=1
gpgcheck=1
repo_gpgcheck=1
gpgkey=https://packages.cloud.google.com/yum/doc/yum-key.gpg https://packages.cloud.google.com/yum/doc/rpm-package-key.gpg
exclude=kube*
EOF
$ yum install -y kubelet kubeadm kubectl cri-tools --disableexcludes=kubernetes

// å¯åŠ¨kubelet
$ systemctl enable kubelet &amp;&amp; systemctl start kubelet
</code></pre></div></div>

<blockquote>
  <p>kubeletç°åœ¨æ¯éš”å‡ ç§’é‡æ–°å¯åŠ¨ä¸€æ¬¡ï¼Œå› ä¸ºå®ƒåœ¨ä¸€ä¸ªcrashloopä¸­ç­‰å¾…kubeadmå‘Šè¯‰å®ƒè¯¥æ€ä¹ˆåšã€‚</p>
</blockquote>

<h3 id="ä½¿ç”¨kubeadmå®‰è£…k8s">ä½¿ç”¨kubeadmå®‰è£…k8s</h3>
<blockquote>
  <p>è¿™é‡ŒæŒ‡å®šäº†ç‰ˆæœ¬å’Œpodçš„ipèŒƒå›´æ®µï¼ŒæŠŠttlè®¾ç½®ä¸ºæ°¸ä¸è¿‡æœŸã€‚</p>
</blockquote>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>$ kubeadm init --kubernetes-version=v1.13.4 --pod-network-cidr=172.80.0.0/16 --token-ttl=0
[init] Using Kubernetes version: v1.13.4
[preflight] Running pre-flight checks
[preflight] Pulling images required for setting up a Kubernetes cluster
[preflight] This might take a minute or two, depending on the speed of your internet connection
[preflight] You can also perform this action in beforehand using 'kubeadm config images pull'
[kubelet-start] Writing kubelet environment file with flags to file "/var/lib/kubelet/kubeadm-flags.env"
[kubelet-start] Writing kubelet configuration to file "/var/lib/kubelet/config.yaml"
[kubelet-start] Activating the kubelet service
[certs] Using certificateDir folder "/etc/kubernetes/pki"
[certs] Generating "ca" certificate and key
[certs] Generating "apiserver" certificate and key
[certs] apiserver serving cert is signed for DNS names [kube-master kubernetes kubernetes.default kubernetes.default.svc kubernetes.default.svc.cluster.local] and IPs [10.96.0.1 192.168.193.64]
[certs] Generating "apiserver-kubelet-client" certificate and key
[certs] Generating "front-proxy-ca" certificate and key
[certs] Generating "front-proxy-client" certificate and key
[certs] Generating "etcd/ca" certificate and key
[certs] Generating "etcd/healthcheck-client" certificate and key
[certs] Generating "apiserver-etcd-client" certificate and key
[certs] Generating "etcd/server" certificate and key
[certs] etcd/server serving cert is signed for DNS names [kube-master localhost] and IPs [192.168.193.64 127.0.0.1 ::1]
[certs] Generating "etcd/peer" certificate and key
[certs] etcd/peer serving cert is signed for DNS names [kube-master localhost] and IPs [192.168.193.64 127.0.0.1 ::1]
[certs] Generating "sa" key and public key
[kubeconfig] Using kubeconfig folder "/etc/kubernetes"
[kubeconfig] Writing "admin.conf" kubeconfig file
[kubeconfig] Writing "kubelet.conf" kubeconfig file
[kubeconfig] Writing "controller-manager.conf" kubeconfig file
[kubeconfig] Writing "scheduler.conf" kubeconfig file
[control-plane] Using manifest folder "/etc/kubernetes/manifests"
[control-plane] Creating static Pod manifest for "kube-apiserver"
[control-plane] Creating static Pod manifest for "kube-controller-manager"
[control-plane] Creating static Pod manifest for "kube-scheduler"
[etcd] Creating static Pod manifest for local etcd in "/etc/kubernetes/manifests"
[wait-control-plane] Waiting for the kubelet to boot up the control plane as static Pods from directory "/etc/kubernetes/manifests". This can take up to 4m0s
[apiclient] All control plane components are healthy after 31.004730 seconds
[uploadconfig] storing the configuration used in ConfigMap "kubeadm-config" in the "kube-system" Namespace
[kubelet] Creating a ConfigMap "kubelet-config-1.13" in namespace kube-system with the configuration for the kubelets in the cluster
[patchnode] Uploading the CRI Socket information "/var/run/dockershim.sock" to the Node API object "kube-master" as an annotation
[mark-control-plane] Marking the node kube-master as control-plane by adding the label "node-role.kubernetes.io/master=''"
[mark-control-plane] Marking the node kube-master as control-plane by adding the taints [node-role.kubernetes.io/master:NoSchedule]
[bootstrap-token] Using token: 5w1erh.y9g8pqqrydfdvjtd
[bootstrap-token] Configuring bootstrap tokens, cluster-info ConfigMap, RBAC Roles
[bootstraptoken] configured RBAC rules to allow Node Bootstrap tokens to post CSRs in order for nodes to get long term certificate credentials
[bootstraptoken] configured RBAC rules to allow the csrapprover controller automatically approve CSRs from a Node Bootstrap Token
[bootstraptoken] configured RBAC rules to allow certificate rotation for all node client certificates in the cluster
[bootstraptoken] creating the "cluster-info" ConfigMap in the "kube-public" namespace
[addons] Applied essential addon: CoreDNS
[addons] Applied essential addon: kube-proxy

Your Kubernetes master has initialized successfully!

To start using your cluster, you need to run the following as a regular user:

  mkdir -p $HOME/.kube
  sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config
  sudo chown $(id -u):$(id -g) $HOME/.kube/config

You should now deploy a pod network to the cluster.
Run "kubectl apply -f [podnetwork].yaml" with one of the options listed at:
  https://kubernetes.io/docs/concepts/cluster-administration/addons/

You can now join any number of machines by running the following on each node
as root:

  kubeadm join 192.168.193.64:6443 --token 5w1erh.y9g8pqqrydfdvjtd --discovery-token-ca-cert-hash sha256:4b817b3481b0e2476979559f8afdcd8f68c1f8e64dd9473a8e3e28bab90816dd
</code></pre></div></div>

<p>è¿™ä¸ªæ—¶å€™ï¼Œæˆ‘ä»¬è¿˜ä¸èƒ½é€šè¿‡kubectlæ¥æ§åˆ¶é›†ç¾¤ï¼Œè¦è®©kubectlå¯ç”¨ï¼Œæˆ‘ä»¬éœ€è¦åšï¼š</p>
<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code># å¯¹äºérootç”¨æˆ·
$ mkdir -p $HOME/.kube
$ sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config
$ sudo chown $(id -u):$(id -g) $HOME/.kube/config

# å¯¹äºrootç”¨æˆ·
$ export KUBECONFIG=/etc/kubernetes/admin.conf
# ä¹Ÿå¯ä»¥ç›´æ¥æ”¾åˆ°~/.bash_profile
$ echo "export KUBECONFIG=/etc/kubernetes/admin.conf" &gt;&gt; ~/.bash_profile
</code></pre></div></div>

<p>æŸ¥çœ‹é›†ç¾¤çŠ¶æ€</p>
<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>$ kubectl get cs
NAME                 STATUS    MESSAGE              ERROR
controller-manager   Healthy   ok                   
scheduler            Healthy   ok                   
etcd-0               Healthy   {"health": "true"} 
</code></pre></div></div>

<h3 id="å®‰è£…ç½‘ç»œæ’ä»¶">å®‰è£…ç½‘ç»œæ’ä»¶</h3>
<p>æ¯”è¾ƒå¸¸è§çš„network addonæœ‰ï¼š Calico, Canal, Flannel, Kube-router, Romana, Weave Netç­‰ã€‚è¿™é‡Œæˆ‘ä»¬ä½¿ç”¨Flannelã€‚</p>

<p><strong>1.ä¸‹è½½flannelæ‰€éœ€yaml</strong></p>
<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>[root@kube-master ~]# wget https://raw.githubusercontent.com/coreos/flannel/a70459be0084506e4ec919aa1c114638878db11b/Documentation/kube-flannel.yml
</code></pre></div></div>

<p><strong>2.ä¿®æ”¹flanneç½‘æ®µ</strong></p>

<blockquote>
  <p>flannelç½‘æ®µä¿®æ”¹æˆkubeadm init â€“pod-network-cidrè¿™ä¸ªç½‘æ®µç›¸åŒçš„</p>
</blockquote>

<div class="language-yaml highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="na">apiVersion</span><span class="pi">:</span> <span class="s">v1</span>
<span class="na">kind</span><span class="pi">:</span> <span class="s">ServiceAccount</span>
<span class="na">metadata</span><span class="pi">:</span>
  <span class="na">name</span><span class="pi">:</span> <span class="s">flannel</span>
  <span class="na">namespace</span><span class="pi">:</span> <span class="s">kube-system</span>
<span class="nn">---</span>
<span class="na">kind</span><span class="pi">:</span> <span class="s">ConfigMap</span>
<span class="na">apiVersion</span><span class="pi">:</span> <span class="s">v1</span>
<span class="na">metadata</span><span class="pi">:</span>
  <span class="na">name</span><span class="pi">:</span> <span class="s">kube-flannel-cfg</span>
  <span class="na">namespace</span><span class="pi">:</span> <span class="s">kube-system</span>
  <span class="na">labels</span><span class="pi">:</span>
    <span class="na">tier</span><span class="pi">:</span> <span class="s">node</span>
    <span class="na">app</span><span class="pi">:</span> <span class="s">flannel</span>
<span class="na">data</span><span class="pi">:</span>
  <span class="s">cni-conf.json</span><span class="pi">:</span> <span class="pi">|</span>
    <span class="s">{</span>
      <span class="s">"name": "cbr0",</span>
      <span class="s">"plugins": [</span>
        <span class="s">{</span>
          <span class="s">"type": "flannel",</span>
          <span class="s">"delegate": {</span>
            <span class="s">"hairpinMode": true,</span>
            <span class="s">"isDefaultGateway": true</span>
          <span class="s">}</span>
        <span class="s">},</span>
        <span class="s">{</span>
          <span class="s">"type": "portmap",</span>
          <span class="s">"capabilities": {</span>
            <span class="s">"portMappings": true</span>
          <span class="s">}</span>
        <span class="s">}</span>
      <span class="s">]</span>
    <span class="s">}</span>
  <span class="s">net-conf.json</span><span class="pi">:</span> <span class="pi">|</span>
    <span class="s">{</span>
      <span class="s">"Network": "173.80.0.0/16",</span>
      <span class="s">"Backend": {</span>
        <span class="s">"Type": "vxlan"</span>
      <span class="s">}</span>
    <span class="s">}</span>
</code></pre></div></div>

<p><strong>3.åˆ›å»ºkube-flannel</strong></p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>[root@kube-master ~]# kubectl create -f kube-flannel.yml
</code></pre></div></div>

<p>é»˜è®¤podä¸ä¼šåœ¨masterä¸Šè°ƒåº¦podï¼Œå¦‚æœæƒ³åœ¨masterä¸Šè°ƒåº¦podæ‰§è¡Œä»¥ä¸‹æŒ‡ä»¤</p>
<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>[root@kube-master ~]# kubectl taint nodes --all node-role.kubernetes.io/master-
</code></pre></div></div>

<h3 id="åŠ å…¥nodeèŠ‚ç‚¹">åŠ å…¥nodeèŠ‚ç‚¹</h3>

<p><strong>1.å¯åŠ¨kubelet</strong></p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>[root@kube-node1~]# systemctl enable kubelet &amp;&amp; systemctl start kubelet
</code></pre></div></div>

<p><strong>2.åŠ å…¥é›†ç¾¤</strong></p>
<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>[root@kube-node1 ~]#   kubeadm join 192.168.193.64:6443 --token 5w1erh.y9g8pqqrydfdvjtd --discovery-token-ca-cert-hash sha256:4b817b3481b0e2476979559f8afdcd8f68c1f8e64dd9473a8e3e28bab90816dd
[preflight] Running pre-flight checks
	[WARNING Hostname]: hostname "kube-node1" could not be reached
	[WARNING Hostname]: hostname "kube-node1": lookup kube-node1 on 8.8.8.8:53: no such host
[discovery] Trying to connect to API Server "192.168.193.64:6443"
[discovery] Created cluster-info discovery client, requesting info from "https://192.168.193.64:6443"
[discovery] Requesting info from "https://192.168.193.64:6443" again to validate TLS against the pinned public key
[discovery] Cluster info signature and contents are valid and TLS certificate validates against pinned roots, will use API Server "192.168.193.64:6443"
[discovery] Successfully established connection with API Server "192.168.193.64:6443"
[join] Reading configuration from the cluster...
[join] FYI: You can look at this config file with 'kubectl -n kube-system get cm kubeadm-config -oyaml'
[kubelet] Downloading configuration for the kubelet from the "kubelet-config-1.13" ConfigMap in the kube-system namespace
[kubelet-start] Writing kubelet configuration to file "/var/lib/kubelet/config.yaml"
[kubelet-start] Writing kubelet environment file with flags to file "/var/lib/kubelet/kubeadm-flags.env"
[kubelet-start] Activating the kubelet service
[tlsbootstrap] Waiting for the kubelet to perform the TLS Bootstrap...
[patchnode] Uploading the CRI Socket information "/var/run/dockershim.sock" to the Node API object "kube-node1" as an annotation

This node has joined the cluster:
* Certificate signing request was sent to apiserver and a response was received.
* The Kubelet was informed of the new secure connection details.

Run 'kubectl get nodes' on the master to see this node join the cluster.
</code></pre></div></div>

<p><strong>4.æŸ¥çœ‹èŠ‚ç‚¹åŠ å…¥æ˜¯å¦æˆåŠŸ</strong></p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>[root@kube-master ~]# kubectl get nodes  --show-labels
NAME          STATUS   ROLES    AGE   VERSION   LABELS
kube-master   Ready    master   11h   v1.13.4   beta.kubernetes.io/arch=amd64,beta.kubernetes.io/os=linux,kubernetes.io/hostname=kube-master,node-role.kubernetes.io/master=
kube-node1    Ready    &lt;none&gt;   10h   v1.13.4   beta.kubernetes.io/arch=amd64,beta.kubernetes.io/os=linux,kubernetes.io/hostname=kube-node1
kube-node2    Ready    &lt;none&gt;   10h   v1.13.4   beta.kubernetes.io/arch=amd64,beta.kubernetes.io/os=linux,kubernetes.io/hostname=kube-node2

</code></pre></div></div>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>[root@kube-master ~]# kubectl get pod --all-namespaces  -o wide
NAMESPACE     NAME                                  READY   STATUS    RESTARTS   AGE   IP               NODE          NOMINATED NODE   READINESS GATES
kube-system   coredns-86c58d9df4-bwtzw              1/1     Running   0          11h   172.80.0.2       kube-master   &lt;none&gt;           &lt;none&gt;
kube-system   coredns-86c58d9df4-lkzcx              1/1     Running   0          11h   172.80.0.3       kube-master   &lt;none&gt;           &lt;none&gt;
kube-system   etcd-kube-master                      1/1     Running   0          11h   192.168.193.64   kube-master   &lt;none&gt;           &lt;none&gt;
kube-system   kube-apiserver-kube-master            1/1     Running   0          11h   192.168.193.64   kube-master   &lt;none&gt;           &lt;none&gt;
kube-system   kube-controller-manager-kube-master   1/1     Running   0          11h   192.168.193.64   kube-master   &lt;none&gt;           &lt;none&gt;
kube-system   kube-flannel-ds-amd64-kjkfc           1/1     Running   0          10h   192.168.193.66   kube-node2    &lt;none&gt;           &lt;none&gt;
kube-system   kube-flannel-ds-amd64-l8sxc           1/1     Running   0          10h   192.168.193.65   kube-node1    &lt;none&gt;           &lt;none&gt;
kube-system   kube-flannel-ds-amd64-wv485           1/1     Running   0          11h   192.168.193.64   kube-master   &lt;none&gt;           &lt;none&gt;
kube-system   kube-proxy-mlpdj                      1/1     Running   0          10h   192.168.193.66   kube-node2    &lt;none&gt;           &lt;none&gt;
kube-system   kube-proxy-mw84r                      1/1     Running   0          10h   192.168.193.65   kube-node1    &lt;none&gt;           &lt;none&gt;
kube-system   kube-proxy-v4vxp                      1/1     Running   0          11h   192.168.193.64   kube-master   &lt;none&gt;           &lt;none&gt;
kube-system   kube-scheduler-kube-master            1/1     Running   0          11h   192.168.193.64   kube-master   &lt;none&gt;           &lt;none&gt;

</code></pre></div></div>

<h3 id="é—®é¢˜">é—®é¢˜</h3>
<p><strong>1.å¦‚æœå®‰è£…è¿‡ç¨‹ä¸­å‡ºç°ä»¥ä¸‹æƒ…å†µä»£è¡¨åœ¨ä¸‹è½½é•œåƒï¼Œè¯·ç§‘å­¦ä¸‹è½½é•œåƒ</strong></p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>[init] Using Kubernetes version: v1.13.4
[preflight] Running pre-flight checks
	[WARNING Hostname]: hostname "kube-master" could not be reached
	[WARNING Hostname]: hostname "kube-master": lookup kube-master on 192.168.106.172:53: server misbehaving
[preflight] Pulling images required for setting up a Kubernetes cluster
[preflight] This might take a minute or two, depending on the speed of your internet connection
[preflight] You can also perform this action in beforehand using 'kubeadm config images pull'
</code></pre></div></div>
<p>æŸ¥çœ‹éœ€è¦ä¸‹è½½é•œåƒ</p>
<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>kubeadm config images list
</code></pre></div></div>

<p><strong>2.kubeletæŠ¥é”™</strong></p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>F0326 10:29:36.382908    4942 server.go:261] failed to run Kubelet: failed to create kubelet: misconfiguration: kubelet cgroup driver: "cgroupfs" is different from docker cgroup driver: "systemd" 
</code></pre></div></div>

<p><strong>è§£å†³æ–¹æ³•ï¼š</strong>
é»˜è®¤ä½¿ç”¨cgroup,è¿™é‡Œæ›´æ”¹ä¸ºsystemdï¼Œå’Œdockerä¸€è‡´ã€‚</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>[root@kube-node1 ~]# vim /etc/systemd/system/kubelet.service.d/10-kubeadm.conf
# Note: This dropin only works with kubeadm and kubelet v1.11+
[Service]
Environment="KUBELET_KUBECONFIG_ARGS=--bootstrap-kubeconfig=/etc/kubernetes/bootstrap-kubelet.conf --kubeconfig=/etc/kubernetes/kubelet.conf"
Environment="KUBELET_CONFIG_ARGS=--config=/var/lib/kubelet/config.yaml"
Environment="KUBELET_CGROUP_ARGS=--cgroup-driver=systemd --runtime-cgroups=/systemd/system.slice --kubelet-cgroups=/systemd/system.slice"
# This is a file that "kubeadm init" and "kubeadm join" generates at runtime, populating the KUBELET_KUBEADM_ARGS variable dynamically
EnvironmentFile=-/var/lib/kubelet/kubeadm-flags.env
# This is a file that the user can use for overrides of the kubelet args as a last resort. Preferably, the user should use
# the .NodeRegistration.KubeletExtraArgs object in the configuration files instead. KUBELET_EXTRA_ARGS should be sourced from this file.
EnvironmentFile=-/etc/sysconfig/kubelet
ExecStart=
ExecStart=/usr/bin/kubelet $KUBELET_KUBECONFIG_ARGS $KUBELET_CONFIG_ARGS $KUBELET_KUBEADM_ARGS $KUBELET_EXTRA_ARGS $KUBELET_CGROUP_ARGS
</code></pre></div></div>

<p><strong>3.kubelet cniæŠ¥é”™</strong></p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>7541 docker_sandbox.go:384] failed to read pod IP from plugin/docker: NetworkPlugin cni failed on the status hook for pod "istio-ingressga...
</code></pre></div></div>

<p><strong>è§£å†³æ–¹æ³•:</strong></p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>[root@kube-node1 ~]# vim /etc/systemd/system/kubelet.service.d/10-kubeadm.conf
# Note: This dropin only works with kubeadm and kubelet v1.11+
[Service]
Environment="KUBELET_KUBECONFIG_ARGS=--bootstrap-kubeconfig=/etc/kubernetes/bootstrap-kubelet.conf --kubeconfig=/etc/kubernetes/kubelet.conf"
Environment="KUBELET_CONFIG_ARGS=--config=/var/lib/kubelet/config.yaml"
Environment="KUBELET_NETWORK_ARGS=--network-plugin=cni --cni-conf-dir=/etc/cni/net.d --cni-bin-dir=/opt/cni/bin"
Environment="KUBELET_CGROUP_ARGS=--cgroup-driver=systemd --runtime-cgroups=/systemd/system.slice --kubelet-cgroups=/systemd/system.slice"
# This is a file that "kubeadm init" and "kubeadm join" generates at runtime, populating the KUBELET_KUBEADM_ARGS variable dynamically
EnvironmentFile=-/var/lib/kubelet/kubeadm-flags.env
# This is a file that the user can use for overrides of the kubelet args as a last resort. Preferably, the user should use
# the .NodeRegistration.KubeletExtraArgs object in the configuration files instead. KUBELET_EXTRA_ARGS should be sourced from this file.
EnvironmentFile=-/etc/sysconfig/kubelet
ExecStart=
ExecStart=/usr/bin/kubelet $KUBELET_KUBECONFIG_ARGS $KUBELET_CONFIG_ARGS $KUBELET_KUBEADM_ARGS $KUBELET_EXTRA_ARGS $KUBELET_CGROUP_ARGS $KUBELET_NETWORK_ARGS
</code></pre></div></div>
:ET